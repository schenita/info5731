{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Floyd_SelfStudy10_part2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schenita/info5731/blob/master/Floyd_SelfStudy10_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "MN4TkBrpPNna",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Schenita Floyd\n",
        "# Self Study 10 Part 2 - Grus: Chapter 11, 13, 17"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ef9S9DArPjdh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Chapter 11 - Machine Learning"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A4Zi1e3rR-Oa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Overfitting and Underfitting"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rcZ9XnTElWD3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def split_data(data, prob):\n",
        "  \"\"\"split data into fractions [prob, 1 - prob]\"\"\" \n",
        "  results = [], []\n",
        "  for row in data:\n",
        "    results[0 if random.random() < prob else 1].append(row) \n",
        "  return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yskdKzcDlXX_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_test_split(x, y, test_pct):\n",
        "  data = zip(x, y)\n",
        "  train, test = split_data(data, 1 - test_pct) \n",
        "  x_train, y_train = zip(*train)\n",
        "  x_test, y_test = zip(*test)\n",
        "  return x_train, x_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ishQsO5zmJcK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "model = mean()\n",
        "x_train, x_test, y_train, y_test = train_test_split(xs, ys, 0.33)\n",
        "model.train(x_train, y_train)\n",
        "performance = model.test(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E5Vjwt2W_hg0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(tp, fp, fn, tn): \n",
        "  correct = tp + tn \n",
        "  total = tp + fp + fn + tn \n",
        "  return correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vw0Vi_jrAYAW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1dc25b7-d367-499d-d875-add0d0770136"
      },
      "cell_type": "code",
      "source": [
        "print accuracy(70, 4930, 13930, 981070)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-3Vri_jvAbfd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def precision(tp, fp, fn, tn):\n",
        "  return tp / (tp + fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OkGlJVohB1ML",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "800174ce-4936-48d5-fcba-c4b3e080ae1a"
      },
      "cell_type": "code",
      "source": [
        "print precision(70, 4930, 13930, 981070)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y-BsXWMqB3wD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e082eab-ec43-433b-8bde-7935ceb1f786"
      },
      "cell_type": "code",
      "source": [
        "def recall(tp, fp, fn, tn): \n",
        "  return tp / (tp + fn)\n",
        "print recall(70, 4930, 13930, 981070)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Pr9j31bXB8iy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def f1_score(tp, fp, fn, tn):\n",
        "    p = precision(tp, fp, fn, tn) \n",
        "    r = recall(tp, fp, fn, tn)\n",
        "\n",
        "    return 2 * p * r / (p+r)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vlRQvvSECG5m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Chapter 13 - Naive Bayes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sVwIPmsJCVRu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokenize(message):\n",
        "    message = message.lower()\n",
        "    all_words = re.findall(\"[a-z0-9']+\", message) \n",
        "    return set(all_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RLfMSSWbCvZD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def count_words(training_set):\n",
        "    \"\"\"training set consists of pairs (message, is_spam)\"\"\" \n",
        "    counts = defaultdict(lambda: [0, 0])\n",
        "    for message, is_spam in training_set:\n",
        "        for word in tokenize(message): \n",
        "          counts[word][0 if is_spam else 1] += 1\n",
        "    return counts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WMPHV9dVC9m-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def word_probabilities(counts, total_spams, total_non_spams, k=0.5): \n",
        "  \"\"\"turn the word_counts into a list of triplets\n",
        "  w, p(w | spam) and p(w | ~spam)\"\"\"\n",
        "  return [(w,\n",
        "          (spam + k) / (total_spams + 2 * k),\n",
        "          (non_spam + k) / (total_non_spams + 2 * k)) \n",
        "          for w, (spam, non_spam) in counts.iteritems()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U3vdmc1aDOiV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def spam_probability(word_probs, message): \n",
        "  message_words = tokenize(message) \n",
        "  log_prob_if_spam = log_prob_if_not_spam = 0.0\n",
        "  for word, prob_if_spam, prob_if_not_spam in word_probs:\n",
        "    if word in message_words:\n",
        "      log_prob_if_spam += math.log(prob_if_spam)\n",
        "      log_prob_if_not_spam += math.log(prob_if_not_spam)\n",
        "\n",
        "    else:\n",
        "      log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
        "      log_prob_if_not_spam += math.log(1.0 - prob_if_not_spam)\n",
        "\n",
        "  prob_if_spam = math.exp(log_prob_if_spam) \n",
        "  prob_if_not_spam = math.exp(log_prob_if_not_spam) \n",
        "  return prob_if_spam / (prob_if_spam + prob_if_not_spam)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uV-3eG4lDWo3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NaiveBayesClassifier:\n",
        "  def __init__(self, k=0.5): \n",
        "    self.k = k\n",
        "    self.word_probs = []\n",
        "    \n",
        "  def train(self, training_set):\n",
        "            # count spam and non-spam messages\n",
        "    num_spams = len([is_spam\n",
        "                    for message, is_spam in training_set\n",
        "                    if is_spam])\n",
        "    num_non_spams = len(training_set) - num_spams\n",
        "            # run training data through our \"pipeline\"\n",
        "    word_counts = count_words(training_set)\n",
        "     self.word_probs = word_probabilities(word_counts,\n",
        "                                          num_spams,\n",
        "                                          num_non_spams,\n",
        "                                          self.k)\n",
        "  def classify(self, message):\n",
        "    return spam_probability(self.word_probs, message)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v0XgIRlhFVNK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob, re\n",
        "\n",
        "    path = r\"C:\\spam\\*\\*\"\n",
        "    data = []\n",
        "    # glob.glob returns every filename that matches the wildcarded path\n",
        "    for fn in glob.glob(path): \n",
        "      is_spam = \"ham\" not in fn\n",
        "      with open(fn,'r') as file: \n",
        "        for line in file:\n",
        "        if line.startswith(\"Subject:\"):\n",
        "            # remove the leading \"Subject: \" and keep what's left \n",
        "            subject = re.sub(r\"^Subject: \", \"\", line).strip() \n",
        "            data.append((subject, is_spam))\n",
        "    random.seed(0) # just so you get the same answers as me \n",
        "    train_data, test_data = split_data(data, 0.75)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ya9sJGEgHK-E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier = NaiveBayesClassifier()\n",
        "classifier.train(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "frTQN0LzHPxl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classified = [(subject, is_spam, classifier.classify(subject)) \n",
        "              for subject, is_spam in test_data]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hUngUdqhHUWj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "counts = Counter((is_spam, spam_probability > 0.5)\n",
        "              for _, is_spam, spam_probability in classified)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rTj4bIshHZFL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classified.sort(key=lambda row: row[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K8BFjrnQHp7h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "spammiest_hams = filter(lambda row: not row[1], classified)[-5:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dWO7QKeZHtEy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hammiest_spams = filter(lambda row: row[1], classified)[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "66pRSe5gHwLZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def p_spam_given_word(word_prob):\n",
        "        \"\"\"uses bayes's theorem to compute p(spam | message contains word)\"\"\"\n",
        "        # word_prob is one of the triplets produced by word_probabilities\n",
        "        word, prob_if_spam, prob_if_not_spam = word_prob \n",
        "        return prob_if_spam / (prob_if_spam + prob_if_not_spam)\n",
        "words = sorted(classifier.word_probs, key=p_spam_given_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qdPBfbcqH-F5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "spammiest_words = words[-5:]\n",
        "hammiest_words = words[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6KMd1Ss0IBsp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def drop_final_s(word):\n",
        "  return re.sub(\"s$\", \"\", word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nL3Sg5n7IG6J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Chapter 17 - Decision Trees"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dtaZ7izMIaEr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def entropy(class_probabilities):\n",
        "    \"\"\"given a list of class probabilities, compute the entropy\"\"\" \n",
        "    return sum(-p * math.log(p, 2)\n",
        "              for p in class_probabilities\n",
        "              if p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "prCQyf3hIypF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def class_probabilities(labels): \n",
        "  total_count = len(labels) \n",
        "  return [count / total_count\n",
        "          for count in Counter(labels).values()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WOpDTlreI5ws",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_entropy(labeled_data):\n",
        "  labels = [label for _, label in labeled_data] \n",
        "  probabilities = class_probabilities(labels) \n",
        "  return entropy(probabilities)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Ip94uQ2JKU8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def partition_entropy(subsets):\n",
        "    \"\"\"find the entropy from this partition of data into subsets subsets is a list of lists of labeled data\"\"\"\n",
        "    total_count = sum(len(subset) for subset in subsets)\n",
        "    return sum( data_entropy(subset) * len(subset) / total_count\n",
        "                for subset in subsets )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JIT1EYMbKvG7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputs = [\n",
        "        ({'level':'Senior', 'lang':'Java', 'tweets':'no', 'phd':'no'}, False), \n",
        "        ({'level':'Senior','lang':'Java','tweets':'no','phd':'yes'}, False), \n",
        "        ({'level':'Mid', 'lang':'Python', 'tweets':'no', 'phd':'no'}, True), \n",
        "        ({'level':'Junior','lang':'Python','tweets':'no','phd':'no'}, True),\n",
        "        ({'level':'Junior', 'lang':'R', 'tweets':'yes', 'phd':'no'},  True),\n",
        "        ({'level':'Junior', 'lang':'R', 'tweets':'yes', 'phd':'yes'}, False),\n",
        "        ({'level':'Mid', 'lang':'R', 'tweets':'yes', 'phd':'yes'},  True),\n",
        "        ({'level':'Senior', 'lang':'Python', 'tweets':'no', 'phd':'no'},  False),\n",
        "        ({'level':'Senior', 'lang':'R', 'tweets':'yes', 'phd':'no'},       True),\n",
        "        ({'level':'Junior', 'lang':'Python', 'tweets':'yes', 'phd':'no'},  True),\n",
        "        ({'level':'Senior', 'lang':'Python', 'tweets':'yes', 'phd':'yes'}, True),\n",
        "        ({'level':'Mid', 'lang':'Python', 'tweets':'no', 'phd':'yes'},     True),\n",
        "        ({'level':'Mid', 'lang':'Java', 'tweets':'yes', 'phd':'no'},       True),\n",
        "        ({'level':'Junior', 'lang':'Python', 'tweets':'no', 'phd':'yes'}, False)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "19fzRHYfK1Iu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def partition_by(inputs, attribute):\n",
        "    \"\"\"each input is a pair (attribute_dict, label) \n",
        "    returns a dict : attribute_value -> inputs\"\"\" \n",
        "    groups = defaultdict(list)\n",
        "    for input in inputs:\n",
        "            key = input[0][attribute]\n",
        "            groups[key].append(input) \n",
        "    return groups"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XVJcagtjLycd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def partition_entropy_by(inputs, attribute):\n",
        "    \"\"\"computes the entropy corresponding to the given partition\"\"\" \n",
        "    partitions = partition_by(inputs, attribute)\n",
        "    return partition_entropy(partitions.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HHEe19AvL7U9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for key in ['level','lang','tweets','phd']: \n",
        "  print key, partition_entropy_by(inputs, key)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "53KHduz-MDMM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02eeb82c-5d77-49ee-c4b2-1a21723b725b"
      },
      "cell_type": "code",
      "source": [
        "senior_inputs = [(input, label)\n",
        "                for input, label in inputs if input[\"level\"] == \"Senior\"]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QY9VbOl1MQJl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for key in ['lang', 'tweets', 'phd']:\n",
        "    print key, partition_entropy_by(senior_inputs, key)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Gf4YT1YMTaM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2496434f-d9cc-4089-ddea-d85d8b6f1deb"
      },
      "cell_type": "code",
      "source": [
        "def classify(tree, input):\n",
        "    \"\"\"classify the input using the given decision tree\"\"\"\n",
        "    # if this is a leaf node, return its value\n",
        "    if tree in [True, False]: \n",
        "      return tree\n",
        "    attribute, subtree_dict = tree\n",
        "    subtree_key = input.get(attribute) \n",
        "    if subtree_key not in subtree_dict:\n",
        "      subtree_key = None\n",
        "    subtree = subtree_dict[subtree_key]\n",
        "    return classify(subtree, input)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i0uY1IQFM1dC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_tree_id3(inputs, split_candidates=None):\n",
        "  if split_candidates is None: \n",
        "    split_candidates = inputs[0][0].keys()\n",
        "    # count Trues and Falses in the inputs\n",
        "  num_inputs = len(inputs)\n",
        "  num_trues = len([label for item, label in inputs if label]) \n",
        "  num_falses = num_inputs - num_trues\n",
        "  \n",
        "  if num_trues == 0: return False\n",
        "  if num_falses == 0: return True\n",
        "  \n",
        "  if not split_candidates:\n",
        "    return num_trues >= num_falses\n",
        "  best_attribute = min(split_candidates,\n",
        "                             key=partial(partition_entropy_by, inputs))\n",
        "  partitions = partition_by(inputs, best_attribute) \n",
        "  new_candidates = [a for a in split_candidates\n",
        "                    if a != best_attribute]\n",
        "  subtrees = { attribute_value : build_tree_id3(subset, new_candidates) \n",
        "              for attribute_value, subset in partitions.iteritems() }\n",
        "  subtrees[None] = num_trues > num_falses  \n",
        "  return (best_attribute, subtrees)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6O6Meom6NUT4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tree = build_tree_id3(inputs)\n",
        "classify(tree, { \"level\" : \"Junior\",\n",
        "                 \"lang\" : \"Java\",\n",
        "                 \"tweets\" : \"yes\",\n",
        "                 \"phd\" : \"no\"} )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CwAFUdLONuwT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classify(tree, { \"level\" : \"Junior\",\n",
        "                 \"lang\" : \"Java\",\n",
        "                 \"tweets\" : \"yes\",\n",
        "                 \"phd\" : \"yes\"} )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xbRjS-f_N0nZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#random forest"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1VTHH7xMN_MW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forest_classify(trees, input):\n",
        "  votes = [classify(tree, input) for tree in trees] \n",
        "  vote_counts = Counter(votes)\n",
        "  return vote_counts.most_common(1)[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cg8GiSc8OC7N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# if there's already few enough split candidates, look at all of them\n",
        "if len(split_candidates) <= self.num_split_candidates: \n",
        "  sampled_split_candidates = split_candidates\n",
        "        # otherwise pick a random sample\n",
        "else:\n",
        "  sampled_split_candidates = random.sample(split_candidates,\n",
        "                                                     self.num_split_candidates)\n",
        "# now choose the best attribute only from those candidates\n",
        "best_attribute = min(sampled_split_candidates,\n",
        "                     key=partial(partition_entropy_by, inputs))\n",
        "partitions = partition_by(inputs, best_attribute)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YbKAK8BPORgM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}