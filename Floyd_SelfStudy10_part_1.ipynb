{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Floyd_SelfStudy10_part_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schenita/info5731/blob/master/Floyd_SelfStudy10_part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fBbZq86DFugd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Schenita Floyd\n",
        "# Self Study 10 Part 1 - NLTK Chapter 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ay2J9EucF-_W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Chapter 6 - Learning to Classify Text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h9Uqx4ziGE_l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A classifier is called supervised if it is built based on training corpora containing the correct label for each input. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2yDwCm1-Hv4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4fccbe3-99f6-45a6-d1fd-38553dd89172"
      },
      "cell_type": "code",
      "source": [
        "# Gender identification\n",
        "def gender_features(word):\n",
        "  return {'last_letter': word[-1]}\n",
        "gender_features('Shrek')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'last_letter': 'k'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "q8NzKeeGMsYi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.corpus import names\n",
        "import random\n",
        "names = ([(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')])\n",
        "random.shuffle(names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KmBXn40LsxCM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
        "rain_set, test_set = featuresets[500:], featuresets[:500]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TpJwzlt2uad9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier.classify(gender_features('Neo'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sm0I8Gz3ubRe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QPLG4leNufmV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " classifier.show_most_informative_features(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PvWoX4PPukPF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.classify import apply_features\n",
        "train_set = apply_features(gender_features, labeled_names[500:])\n",
        "test_set = apply_features(gender_features, labeled_names[:500])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7EYqdtb9usqk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gender_features2(name):\n",
        "    features = {}\n",
        "    features[\"first_letter\"] = name[0].lower()\n",
        "    features[\"last_letter\"] = name[-1].lower()\n",
        "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
        "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
        "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3adSeUMpu0I2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "41531a81-4027-4481-a6d8-e553793817c0"
      },
      "cell_type": "code",
      "source": [
        "gender_features2('John') "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'count(a)': 0,\n",
              " 'count(b)': 0,\n",
              " 'count(c)': 0,\n",
              " 'count(d)': 0,\n",
              " 'count(e)': 0,\n",
              " 'count(f)': 0,\n",
              " 'count(g)': 0,\n",
              " 'count(h)': 1,\n",
              " 'count(i)': 0,\n",
              " 'count(j)': 1,\n",
              " 'count(k)': 0,\n",
              " 'count(l)': 0,\n",
              " 'count(m)': 0,\n",
              " 'count(n)': 1,\n",
              " 'count(o)': 1,\n",
              " 'count(p)': 0,\n",
              " 'count(q)': 0,\n",
              " 'count(r)': 0,\n",
              " 'count(s)': 0,\n",
              " 'count(t)': 0,\n",
              " 'count(u)': 0,\n",
              " 'count(v)': 0,\n",
              " 'count(w)': 0,\n",
              " 'count(x)': 0,\n",
              " 'count(y)': 0,\n",
              " 'count(z)': 0,\n",
              " 'first_letter': 'j',\n",
              " 'has(a)': False,\n",
              " 'has(b)': False,\n",
              " 'has(c)': False,\n",
              " 'has(d)': False,\n",
              " 'has(e)': False,\n",
              " 'has(f)': False,\n",
              " 'has(g)': False,\n",
              " 'has(h)': True,\n",
              " 'has(i)': False,\n",
              " 'has(j)': True,\n",
              " 'has(k)': False,\n",
              " 'has(l)': False,\n",
              " 'has(m)': False,\n",
              " 'has(n)': True,\n",
              " 'has(o)': True,\n",
              " 'has(p)': False,\n",
              " 'has(q)': False,\n",
              " 'has(r)': False,\n",
              " 'has(s)': False,\n",
              " 'has(t)': False,\n",
              " 'has(u)': False,\n",
              " 'has(v)': False,\n",
              " 'has(w)': False,\n",
              " 'has(x)': False,\n",
              " 'has(y)': False,\n",
              " 'has(z)': False,\n",
              " 'last_letter': 'n'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "lMzp-ApNu3RO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "featuresets = [(gender_features2(n), gender) for (n, gender) in labeled_names]\n",
        "train_set, test_set = featuresets[500:], featuresets[:500]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rjzd3vkbu_yu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_names = labeled_names[1500:]\n",
        "devtest_names = labeled_names[500:1500]\n",
        "test_names = labeled_names[:500]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uWOI8Y3UvJrQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
        "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
        "test_set = [(gender_features(n), gender) for (n, gender) in test_names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xHOqiHVIvguv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier = nltk.NaiveBayesClassifier.train(train_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "06VvB35QvmlN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(nltk.classify.accuracy(classifier, devtest_set))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y_NEI8uzvplc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "errors = []\n",
        "for (name, tag) in devtest_names:\n",
        "  guess = classifier.classify(gender_features(name))\n",
        "  if guess != tag:\n",
        "  errors.append( (tag, guess, name) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1wXZmU8zv0m8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for (tag, guess, name) in sorted(errors):\n",
        "  print('correct={:<8} guess={:<8s} name={:<30}'.format(tag, guess, name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zvltURgQv6GL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gender_features(word):\n",
        "  return {'suffix1': word[-1:],\n",
        "          'suffix2': word[-2:]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T56KPvEkwCZa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
        "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, devtest_set))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rb4FlCp7wLeN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Document Classification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KygsSCFewQsA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.corpus import movie_reviews\n",
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "                  for category in movie_reviews.categories()\n",
        "                  for fileid in movie_reviews.fileids(category)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lKk7wyz_wn6x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "random.shuffle(documents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I455aOoawsXw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
        "word_features = list(all_words)[:2000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sjVR_Wrswyik",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def document_features(document): [2]\n",
        "    document_words = set(document) [3]\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features['contains({})'.format(word)] = (word in document_words)\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ePHBYHypw93X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(document_features(movie_reviews.words('pos/cv957_8737.txt'))) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d1VBe40_xBmP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
        "train_set, test_set = featuresets[100:], featuresets[:100]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rH7t8rk5xIH5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s8GZUSa3xMBe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier.show_most_informative_features(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4XprFgC7xPF2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Part-of-Speech Tagging"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q3suaa_6ySsN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.corpus import brown\n",
        "suffix_fdist = nltk.FreqDist()\n",
        "for word in brown.words():\n",
        "    word = word.lower()\n",
        "    suffix_fdist[word[-1:]] += 1\n",
        "    suffix_fdist[word[-2:]] += 1\n",
        "    suffix_fdist[word[-3:]] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oaeP3xiuyl7V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dce87063-04e9-4e5a-ac9c-0b414e7a4e91"
      },
      "cell_type": "code",
      "source": [
        "common_suffixes = [suffix for (suffix, count) in suffix_fdist.most_common(100)]\n",
        "print(common_suffixes)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FNnuGoDuyzit",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pos_features(word):\n",
        "        features = {}\n",
        "        for suffix in common_suffixes:\n",
        "            features['endswith({})'.format(suffix)] = word.lower().endswith(suffix)\n",
        "        return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k0TbXlsMy-Tk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tagged_words = brown.tagged_words(categories='news')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jYPgwLpQzEKN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "featuresets = [(pos_features(n), g) for (n,g) in tagged_words]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0VjzzAKTzJes",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "size = int(len(featuresets) * 0.1)\n",
        "train_set, test_set = featuresets[size:], featuresets[:size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k40cSh6NzPJr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
        "nltk.classify.accuracy(classifier, test_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "__nMlcy3zT0c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier.classify(pos_features('cats'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KYzK1G1_zXfb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(classifier.pseudocode(depth=4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XGcg-QiNzbuy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Exploiting Context"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KLsOBgEqzqDy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pos_features(sentence, i):\n",
        "    features = {\"suffix(1)\": sentence[i][-1:],\n",
        "                \"suffix(2)\": sentence[i][-2:],\n",
        "                \"suffix(3)\": sentence[i][-3:]}\n",
        "    if i == 0:\n",
        "        features[\"prev-word\"] = \"<START>\"\n",
        "    else:\n",
        "        features[\"prev-word\"] = sentence[i-1]\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bk1G_DK8z0qr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pos_features(brown.sents()[0], 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O8E7MToHz7io",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tagged_sents = brown.tagged_sents(categories='news')\n",
        "featuresets = []\n",
        "for tagged_sent in tagged_sents:\n",
        "        untagged_sent = nltk.tag.untag(tagged_sent)\n",
        "        for i, (word, tag) in enumerate(tagged_sent):\n",
        "            featuresets.append( (pos_features(untagged_sent, i), tag) )\n",
        "\n",
        "size = int(len(featuresets) * 0.1)\n",
        "train_set, test_set = featuresets[size:], featuresets[:size]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "nltk.classify.accuracy(classifier, test_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yoSZZFXM0G6n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Sequence Classification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OyPw7eMF0dv7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " def pos_features(sentence, i, history): \n",
        "     features = {\"suffix(1)\": sentence[i][-1:],\n",
        "                 \"suffix(2)\": sentence[i][-2:],\n",
        "                 \"suffix(3)\": sentence[i][-3:]}\n",
        "     if i == 0:\n",
        "         features[\"prev-word\"] = \"<START>\"\n",
        "         features[\"prev-tag\"] = \"<START>\"\n",
        "     else:\n",
        "         features[\"prev-word\"] = sentence[i-1]\n",
        "         features[\"prev-tag\"] = history[i-1]\n",
        "     return features\n",
        "\n",
        "class ConsecutivePosTagger(nltk.TaggerI): \n",
        "\n",
        "    def __init__(self, train_sents):\n",
        "        train_set = []\n",
        "        for tagged_sent in train_sents:\n",
        "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
        "            history = []\n",
        "            for i, (word, tag) in enumerate(tagged_sent):\n",
        "                featureset = pos_features(untagged_sent, i, history)\n",
        "                train_set.append( (featureset, tag) )\n",
        "                history.append(tag)\n",
        "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "    def tag(self, sentence):\n",
        "        history = []\n",
        "        for i, word in enumerate(sentence):\n",
        "            featureset = pos_features(sentence, i, history)\n",
        "            tag = self.classifier.classify(featureset)\n",
        "            history.append(tag)\n",
        "        return zip(sentence, history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i6UhsScy0jzy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tagged_sents = brown.tagged_sents(categories='news')\n",
        "size = int(len(tagged_sents) * 0.1)\n",
        "train_sents, test_sents = tagged_sents[size:], tagged_sents[:size]\n",
        "tagger = ConsecutivePosTagger(train_sents)\n",
        "print(tagger.evaluate(test_sents))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "af2J2Dua0y5h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Sentence Segmentation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rWsWHa3t08Un",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sents = nltk.corpus.treebank_raw.sents()\n",
        "tokens = []\n",
        "boundaries = set()\n",
        "offset = 0\n",
        "for sent in sents:\n",
        "    tokens.extend(sent)\n",
        "    offset += len(sent)\n",
        "    boundaries.add(offset-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iwMBCJFy1IZm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def punct_features(tokens, i):\n",
        "    return {'next-word-capitalized': tokens[i+1][0].isupper(),\n",
        "              'prev-word': tokens[i-1].lower(),\n",
        "              'punct': tokens[i],\n",
        "              'prev-word-is-one-char': len(tokens[i-1]) == 1}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iT6MDJ4b1rUO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "featuresets = [(punct_features(tokens, i), (i in boundaries))\n",
        "               for i in range(1, len(tokens)-1)\n",
        "               if tokens[i] in '.?!']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "87d3Qwe31061",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "size = int(len(featuresets) * 0.1)\n",
        "train_set, test_set = featuresets[size:], featuresets[:size]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "nltk.classify.accuracy(classifier, test_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Wst4R8M2GOF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def segment_sentences(words):\n",
        "    start = 0\n",
        "    sents = []\n",
        "    for i, word in enumerate(words):\n",
        "        if word in '.?!' and classifier.classify(punct_features(words, i)) == True:\n",
        "            sents.append(words[start:i+1])\n",
        "            start = i+1\n",
        "    if start < len(words):\n",
        "        sents.append(words[start:])\n",
        "    return sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Am-Ih5tY4fdZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Identifying Dialogue Act Types"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X0A3FVeG4kwx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "posts = nltk.corpus.nps_chat.xml_posts()[:10000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8WLd084n4rPp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dialogue_act_features(post):\n",
        "        features = {}\n",
        "        for word in nltk.word_tokenize(post):\n",
        "            features['contains({})'.format(word.lower())] = True\n",
        "        return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2HaoOXaS5GfE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "featuresets = [(dialogue_act_features(post.text), post.get('class'))\n",
        "               for post in posts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k9ZkMSyW5Sio",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "size = int(len(featuresets) * 0.1)\n",
        "train_set, test_set = featuresets[size:], featuresets[:size]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bkn2U5xo59xU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Recognizing Textual Entailment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-a7S-xkd6BIM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rte_features(rtepair):\n",
        "    extractor = nltk.RTEFeatureExtractor(rtepair)\n",
        "    features = {}\n",
        "    features['word_overlap'] = len(extractor.overlap('word'))\n",
        "    features['word_hyp_extra'] = len(extractor.hyp_extra('word'))\n",
        "    features['ne_overlap'] = len(extractor.overlap('ne'))\n",
        "    features['ne_hyp_extra'] = len(extractor.hyp_extra('ne'))\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6G5gIQBl6NZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46e4e3f7-66a5-4c35-9aaf-259c46bf5863"
      },
      "cell_type": "code",
      "source": [
        "rte_features"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.rte_features>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "tffBJ6kK6P24",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rtepair = nltk.corpus.rte.pairs(['rte3_dev.xml'])[33]\n",
        "extractor = nltk.RTEFeatureExtractor(rtepair)\n",
        "print(extractor.text_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eV73Jmh86eXb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(extractor.hyp_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ra34jwCb6kwT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(extractor.overlap('word'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t5JZPVNG6n0y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(extractor.overlap('ne'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I_FlSNFG6rua",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(extractor.hyp_extra('word'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3COqbZw-6yoY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The Test Set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_eGOUnTb7ALF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "from nltk.corpus import brown\n",
        "tagged_sents = list(brown.tagged_sents(categories='news'))\n",
        "random.shuffle(tagged_sents)\n",
        "size = int(len(tagged_sents) * 0.1)\n",
        "train_set, test_set = tagged_sents[size:], tagged_sents[:size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "plEmM9XN7Lr3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_ids = brown.fileids(categories='news')\n",
        "size = int(len(file_ids) * 0.1)\n",
        "train_set = brown.tagged_sents(file_ids[size:])\n",
        "test_set = brown.tagged_sents(file_ids[:size])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y4X6uV2P7hOE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_set = brown.tagged_sents(categories='news')\n",
        "test_set = brown.tagged_sents(categories='fiction')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d37ZegKj7qtV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_t8S6DbD7vj9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier = nltk.NaiveBayesClassifier.train(train_set) \n",
        "print('Accuracy: {:4.2f}'.format(nltk.classify.accuracy(classifier, test_set))) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TWiupWTO79Vw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Confusion Matrices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jbMolpow8GS3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tag_list(tagged_sents):\n",
        "  return [tag for sent in tagged_sents for (word, tag) in sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xMIl27sy8LeB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def apply_tagger(tagger, corpus):\n",
        "  return [tagger.tag(nltk.tag.untag(sent)) for sent in corpus]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "04Fe4tJq8P1W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gold = tag_list(brown.tagged_sents(categories='editorial'))\n",
        "test = tag_list(apply_tagger(t2, brown.tagged_sents(categories='editorial')))\n",
        "cm = nltk.ConfusionMatrix(gold, test)\n",
        "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VsGzXv4u8VH-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Entropy and Information Gain"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vA6mpOpq8glQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "def entropy(labels):\n",
        "    freqdist = nltk.FreqDist(labels)\n",
        "    probs = [freqdist.freq(l) for l in freqdist]\n",
        "    return -sum(p * math.log(p,2) for p in probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VI-b94Iu88JG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9709be7b-75fe-4213-c8f2-0c3197172d6d"
      },
      "cell_type": "code",
      "source": [
        "print(entropy(['male', 'male', 'male', 'male'])) "
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dEQJh_mc9Lkg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76a40243-782f-438b-df8c-8f3d4df87ba1"
      },
      "cell_type": "code",
      "source": [
        "print(entropy(['male', 'female', 'male', 'male']))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8112781244591328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nZmyXjVD9OBv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41f062c1-efa7-4917-b03d-15e0449c255e"
      },
      "cell_type": "code",
      "source": [
        "print(entropy(['female', 'male', 'female', 'male']))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JEA1q_0m9RMo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04d00af7-7ac2-46a7-f68b-8d9197762db8"
      },
      "cell_type": "code",
      "source": [
        "print(entropy(['female', 'female', 'male', 'female']))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8112781244591328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3PJMnVfl9U2f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7002923d-94f1-45c8-b85d-a407213bc09e"
      },
      "cell_type": "code",
      "source": [
        "print(entropy(['female', 'female', 'female', 'female'])) "
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RZ_xOnlG-7Ok",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}